# -*- coding: utf-8 -*-
""" Dog with pre-trained weights
Created on Mon Jan 22 12:28:00 2018
Kaggle Dog Breed Identification using Keras running Tensorflow backend
Doggies are cute, Woof Woof Woof 

@author: Carmen Su 
"""
import os
import cv2 # image handling
import pandas as pd
import numpy as np 
from tqdm import tqdm

import seaborn as sns
import matplotlib.pyplot as plt 

from sklearn.cross_validation import train_test_split
from sklearn.linear_model import LogisticRegression

import keras
from keras.models import Model, Sequential
from keras.applications.vgg19 import VGG19
from keras.applications.vgg16 import VGG16
from keras.layers import Dense, Activation, Flatten, Dropout, Input

print ('Examine the labels & set Y_train')
lables = pd.read_csv('labels.csv')
print (lables.head(5))
breed_count = lables['breed'].value_counts()
print (breed_count.head())
print (breed_count.shape)

# breed visualisation 
ax = pd.value_counts(lables['breed'],ascending=True).plot(kind='barh',
                                                       fontsize="40",
                                                       title="Class Distribution",
                                                       figsize=(50,100))
ax.set(xlabel="Images per class", ylabel="Classes")
ax.xaxis.label.set_size(40)
ax.yaxis.label.set_size(40)
ax.title.set_size(60)

# target one hot encoding 
targets = pd.Series(lables['breed'])
one_hot = pd.get_dummies(targets, sparse = True)
one_hot_labels = np.asarray(one_hot)
        
print ('Import trainning images & and tranfer them into arrays')
img_rows = 64
img_cols = 64
num_channel = 3 # 3 colour channes

# testing cv2 for a single image
path = 'C:\\Users\\jiawe\\Dropbox\\Data Science Projects\\Dog'
'''
img_1 = cv2.imread(path+'\\train\\'+'000bec180eb18c7604dcecc8fe0dba07.jpg', 0)
img_1_resize= cv2.resize(img_1, (img_rows, img_cols)) 
cv2.imshow('Single Image', img_1_resize)
cv2.waitKey(0)
cv2.destroyAllWindows()
'''

print ('image listing, iterate all images in the train folder')
x_feature = []
y_feature = []

i = 0 # initialisation
for f, img in tqdm(lables.values): # f for format ,jpg
    train_img = cv2.imread(path + '\\train\\{}.jpg'.format(f))
    label = one_hot_labels[i]
    train_img_resize = cv2.resize(train_img, (img_rows, img_cols)) 
    x_feature.append(train_img_resize)
    y_feature.append(label)
    i += 1
    
print ('transform data each datum into an array')
x_train_data = np.array(x_feature, np.float32) / 255.   # /= 255 for normolisation
# x_train_data = np.expand_dims(x_train_data, axis = 3) # for grayscale
y_train_data = np.array(y_feature, np.uint8)
print (x_train_data.shape)
print (y_train_data.shape)

num_class = y_train_data.shape[1]

print ('prepare test data')        
submission = pd.read_csv('sample_submission.csv')
test_img = submission['id']

x_test_feature = []

i = 0 # initialisation
for f in tqdm(test_img.values): # f for format ,jpg
    img = cv2.imread(path + '\\test\\{}.jpg'.format(f))
    img_resize = cv2.resize(img, (img_rows, img_cols)) 
    x_test_feature.append(img_resize)  
    
x_test_data = np.array(x_test_feature, np.float32) / 255. 
# x_test_data = np.expand_dims(x_test_data, axis = 3)
print (x_test_data.shape)

x_train, x_val, y_train, y_val = train_test_split(x_train_data, y_train_data, test_size=0.1,  random_state=2)

print ('Building the model with pre-trained weights')
base_model = VGG16(include_top=False, input_shape=(224, 224, 3))
# Add a new top layer
x = base_model.output
x = Flatten()(x)
predictions = Dense(num_class, activation='softmax')(x)
# This is the model we will train
model = Model(inputs=base_model.input, outputs=predictions)
# First: train only the top layers (which were randomly initialized)
for layer in base_model.layers:
    layer.trainable = False

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]
model.summary()

# feed images into ANN
batch_size = 32 
nb_epochs = 10
history = model.fit(x_train, y_train,
                    batch_size=batch_size,
                    epochs=nb_epochs,
                    verbose=2, 
                    validation_data=(x_val, y_val),
                    initial_epoch=0)
score = model.evaluate(x_val, y_val, verbose=0)
print('\nKeras CNN #2 - accuracy:', score[1], '\n')

# predict results
results = model.predict(x_test_data)
prediction = pd.DataFrame(results)

# Set column names to those generated by the one-hot encoding earlier
col_names = one_hot.columns.values
prediction.columns = col_names
# Insert the column id from the sample_submission at the start of the data frame
prediction.insert(0, 'id', submission['id'])

submission = prediction
submission.to_csv('new_submission.csv', index=False)

end = dt.datetime.now()
print('Total time {} s.'.format((end - start).seconds))